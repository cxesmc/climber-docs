{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to CLIMBER-X , a fast Earth system model. CLIMBER-X simulates the response of the Earth system to changes in different climate forcings, such as changes in greenhouse gas concentrations or in the Earth's orbital configuration. To do so the model represents the physical processes in atmosphere, ocean and on land that determine the climate state of the Earth. It also simulates the bio- and geochemical processes in the biosphere, soil, ocean and marine sediments and therefore allows for an interactive determination of the atmospheric CO2 and methane concentrations. CLIMBER-X also includes two different models for the continental ice sheets and a model for the response of the solid Earth to changes in surface load. Specifically, the model includes the following components: SESAM: semi-empirical statistical-dynamical atmosphere model GOLDSTEIN: 3-D frictional-geostrophic ocean model HAMOCC: ocean and sediments carbon cycle model SISIM: sea ice model PALADYN: land model Yelmo or SICOPOLIS: ice sheet models VILMA: viscoelastic lithosphere and mantle model The general CLIMBER-X design and the details of the climate model component are described in the following article: Willeit, M., Ganopolski, A., Robinson, A., and Edwards, N. R.: The Earth system model CLIMBER-X v1.0 \u2013 Part 1: Climate model description and validation, Geosci. Model Dev., 15, 5905\u20135948, https://doi.org/10.5194/gmd-15-5905-2022 , 2022. The global carbon cycle model of CLIMBER-X is described in: Willeit, M., Ilyina, T., Liu, B., Heinze, C., Perrette, M., Heinemann, M., Dalmonech, D., Brovkin, V., Munhoven, G., B\u00f6rker, J., Hartmann, J., Romero-Mujalli, G., and Ganopolski, A.: The Earth system model CLIMBER-X v1.0 \u2013 Part 2: The global carbon cycle, Geosci. Model Dev., 16, 3501\u20133534, https://doi. org/10.5194/gmd-16-3501-2023 , 2023. The ice sheet model coupling and the ice sheet surface mass balance scheme are described in: Willeit, M., Calov, R., Talento, S., Greve, R., Bernales, J., Klemann, V., Bagge, M., and Ganopolski, A.: Glacial inception through rapid ice area increase driven by albedo and vegetation feedbacks, Clim. Past, 20, 597\u2013623, https://doi.org/10.5194/cp-20-597-2024 , 2024. The CLIMBER-X code repository can be found here: https://github.com/cxesmc/climber-x See Getting started to see how to get the code, compile a test program and run simulations.","title":"Home"},{"location":"TODO/","text":"TO DO Update docs with latest compilation instructions. Delete compiled Yelmo version. Add real(...,sp) wrapper to writing yelmo output in ice_model::yelmo_write_step_2D() . Get climber-clim version compiling with gfortran . Delete compiled coordinates version. Add instructions to download coordinates and configure it. Consider removing dummy geo and bgc, and rather use preprocessor statements. At least for VILMA, this probably makes a lot of sense. For bgc, perhaps see below to make dummy usage easier. Where possible, make _def.f90 files for model components, so that the derived types are defined separately from the model itself. Then remaining dummy files will be much smaller and easier to maintain. Compilation Make different compilation commands for different sections of the code (could help with compiling during development phases, to avoid repeatedly compiling full code) Make default model version the minimal version without major dependencies. Find out how to check which Makefile 'target' was called, to be able to properly set the LDFLAGS (LFLAGS+FFLAGS) climber-clim: minimal configuration with ocn,atm,lnd,sic climber-clim-bgc: plus with bgc climber-clim-ice climber-clim-bgc-ice climber: climber-clim-bgc-ice atm bgc bnd ch4 co2 geo ice ice_sico imo lnd lndvc main ocn sic smb utils vilma yelmo: yelmo-static possible later options: ice-yelmo ice-sico","title":"TO DO"},{"location":"TODO/#to-do","text":"Update docs with latest compilation instructions. Delete compiled Yelmo version. Add real(...,sp) wrapper to writing yelmo output in ice_model::yelmo_write_step_2D() . Get climber-clim version compiling with gfortran . Delete compiled coordinates version. Add instructions to download coordinates and configure it. Consider removing dummy geo and bgc, and rather use preprocessor statements. At least for VILMA, this probably makes a lot of sense. For bgc, perhaps see below to make dummy usage easier. Where possible, make _def.f90 files for model components, so that the derived types are defined separately from the model itself. Then remaining dummy files will be much smaller and easier to maintain.","title":"TO DO"},{"location":"TODO/#compilation","text":"Make different compilation commands for different sections of the code (could help with compiling during development phases, to avoid repeatedly compiling full code) Make default model version the minimal version without major dependencies. Find out how to check which Makefile 'target' was called, to be able to properly set the LDFLAGS (LFLAGS+FFLAGS) climber-clim: minimal configuration with ocn,atm,lnd,sic climber-clim-bgc: plus with bgc climber-clim-ice climber-clim-bgc-ice climber: climber-clim-bgc-ice atm bgc bnd ch4 co2 geo ice ice_sico imo lnd lndvc main ocn sic smb utils vilma yelmo: yelmo-static possible later options: ice-yelmo ice-sico","title":"Compilation"},{"location":"dependencies/","text":"Dependencies CLIMBER-X is dependent on the following libraries: NetCDF: NetCDF library FFTW: Fastest Fourier Transform in the West . The library will have to be compiled from the original source code. coordinates: coordinates , a module to handle grid/points definition, interpolation mapping and subsetting. The library will have to be compiled from the original source code. Needed only if running with coupled ice sheets: Yelmo: Yelmo ice sheet model . The library will have to be compiled from the original source code. LIS: Library of Iterative Solvers for Linear Systems . The library will have to be compiled from the original source code. OPTIONAL: Python 3.x, which is only needed for automatic configuration of the Makefile and the use of the scripts job_climber and runcx for job preparation and submission. CDO: Climate Data Operators , used for more efficient creation of maps to transform between different coordinate grids. runner: 'runner' Python library (alex-robinson fork) Installation tips for each dependency can be found below. Installing NetCDF (preferably version 4.0 or higher) The NetCDF library is typically available with different distributions (Linux, Mac, etc). Along with installing libnetcdf , it will be necessary to install the package libnetcdf-dev . Installing the NetCDF viewing program ncview is also recommended. If you want to install NetCDF from source, then you must install both the netcdf-c and subsequently netcdf-fortran libraries. The source code and installation instructions are available from the Unidata website: https://www.unidata.ucar.edu/software/netcdf/docs/getting_and_building_netcdf.html Installing FFTW Download and configure the FFTW source: https://www.fftw.org/download.html wget https://www.fftw.org/fftw-3.3.10.tar.gz tar -xvf fftw-3.3.10.tar.gz rm fftw-3.3.10.tar.gz mv fftw-3.3.10 fftw cd fftw ./configure --prefix=$PWD --enable-openmp CC=icc F77=ifort make make install Installing coordinates Download the coordinates source: https://github.com/cxesmc/coordinates . Configure the package, and install it in the location of your choice (below defined as $COORDROOT ): git clone git@github.com:cxesmc/coordinates.git $COORDROOT cd $COORDROOT python config.py config/pik_hpc2024_ifx make clean make coord-static openmp=1 Installing LIS Download the LIS source: https://www.ssisc.org/lis/ Configure the package, and install it in the location of your choice (below defined as $LISROOT ). Also, make sure to enable the Fortran90 and openmp interface: git clone git@github.com:anishida/lis.git $LISROOT ./configure --prefix=$LISROOT --enable-omp --enable-f90 make make install Note: make sure to set the environment variables CC and FC , in order to set a specific compiler, for example for gcc/gfortran use the following configure command: CC=gcc FC=gfortran ./configure --prefix=$LISROOT --enable-f90 --enable-omp Installing runner Install runner to your system's Python installation via pip , along with dependency tabulate . pip install https://github.com/alex-robinson/runner/archive/refs/heads/master.zip pip install tabulate That's it! Now check that system command job is available by running job -h . Note that install method python setup.py install should be avoided if possible to maintain Python system integrity.","title":"Dependencies"},{"location":"dependencies/#dependencies","text":"CLIMBER-X is dependent on the following libraries: NetCDF: NetCDF library FFTW: Fastest Fourier Transform in the West . The library will have to be compiled from the original source code. coordinates: coordinates , a module to handle grid/points definition, interpolation mapping and subsetting. The library will have to be compiled from the original source code. Needed only if running with coupled ice sheets: Yelmo: Yelmo ice sheet model . The library will have to be compiled from the original source code. LIS: Library of Iterative Solvers for Linear Systems . The library will have to be compiled from the original source code. OPTIONAL: Python 3.x, which is only needed for automatic configuration of the Makefile and the use of the scripts job_climber and runcx for job preparation and submission. CDO: Climate Data Operators , used for more efficient creation of maps to transform between different coordinate grids. runner: 'runner' Python library (alex-robinson fork) Installation tips for each dependency can be found below.","title":"Dependencies"},{"location":"dependencies/#installing-netcdf-preferably-version-40-or-higher","text":"The NetCDF library is typically available with different distributions (Linux, Mac, etc). Along with installing libnetcdf , it will be necessary to install the package libnetcdf-dev . Installing the NetCDF viewing program ncview is also recommended. If you want to install NetCDF from source, then you must install both the netcdf-c and subsequently netcdf-fortran libraries. The source code and installation instructions are available from the Unidata website: https://www.unidata.ucar.edu/software/netcdf/docs/getting_and_building_netcdf.html","title":"Installing NetCDF (preferably version 4.0 or higher)"},{"location":"dependencies/#installing-fftw","text":"Download and configure the FFTW source: https://www.fftw.org/download.html wget https://www.fftw.org/fftw-3.3.10.tar.gz tar -xvf fftw-3.3.10.tar.gz rm fftw-3.3.10.tar.gz mv fftw-3.3.10 fftw cd fftw ./configure --prefix=$PWD --enable-openmp CC=icc F77=ifort make make install","title":"Installing FFTW"},{"location":"dependencies/#installing-coordinates","text":"Download the coordinates source: https://github.com/cxesmc/coordinates . Configure the package, and install it in the location of your choice (below defined as $COORDROOT ): git clone git@github.com:cxesmc/coordinates.git $COORDROOT cd $COORDROOT python config.py config/pik_hpc2024_ifx make clean make coord-static openmp=1","title":"Installing coordinates"},{"location":"dependencies/#installing-lis","text":"Download the LIS source: https://www.ssisc.org/lis/ Configure the package, and install it in the location of your choice (below defined as $LISROOT ). Also, make sure to enable the Fortran90 and openmp interface: git clone git@github.com:anishida/lis.git $LISROOT ./configure --prefix=$LISROOT --enable-omp --enable-f90 make make install Note: make sure to set the environment variables CC and FC , in order to set a specific compiler, for example for gcc/gfortran use the following configure command: CC=gcc FC=gfortran ./configure --prefix=$LISROOT --enable-f90 --enable-omp","title":"Installing LIS"},{"location":"dependencies/#installing-runner","text":"Install runner to your system's Python installation via pip , along with dependency tabulate . pip install https://github.com/alex-robinson/runner/archive/refs/heads/master.zip pip install tabulate That's it! Now check that system command job is available by running job -h . Note that install method python setup.py install should be avoided if possible to maintain Python system integrity.","title":"Installing runner"},{"location":"dir-struct/","text":"Directory structure config/ Configuration files for compilation on different systems. input/ Location of any input data needed by the model. output/ Default location for model output. maps/ Location of the maps that will be generated to map/interpolate between different grids. nml/ Default parameter namelists that manage the model configuration. restart/ Location of the restart files needed to continue previous model simulations. src/ Source code for CLIMBER-X.","title":"Dir struct"},{"location":"dir-struct/#directory-structure","text":"config/ Configuration files for compilation on different systems. input/ Location of any input data needed by the model. output/ Default location for model output. maps/ Location of the maps that will be generated to map/interpolate between different grids. nml/ Default parameter namelists that manage the model configuration. restart/ Location of the restart files needed to continue previous model simulations. src/ Source code for CLIMBER-X.","title":"Directory structure"},{"location":"getting-started/","text":"Getting started Here you can find the basic information and steps needed to get CLIMBER-X running. Some step-by-step commands are given for specific environments. To see how to install CLIMBER-X on the HPC2024 cluster at PIK, see: Running-at-PIK for detailed instructions. There are currently four different flavors of CLIMBER-X that can be set up: climber-clim : minimal climate model configuration with atmosphere, ocean, sea ice and land (including dynamic vegetation) climber-clim-bgc : coupled climate-carbon cycle model configuration; clim plus with ocean biogeochemistry climber-clim-ice : coupled climate-ice sheet model configuration; clim plus with ice sheets climber-clim-bgc-ice : fully coupled model configuration; clim plus with ocean biogeochemistry and ice sheets The model dependencies vary according to the desired model configuration: Dependencies are: NetCDF, FFTW, coordinates Additional dependencies if using coupled ice sheets are: Yelmo, LIS Optional dependencies are: CDO, runner See: Dependencies for more details. Super-quick start A summary of example commands to get started is given below using the ifort compiler. For more detailed information see subsequent sections. ### Download the CLIMBER-X code ### # Clone code repository git clone git@github.com:cxesmc/climber-x.git # Enter directory cd climber-x # Clone input file directory git clone git@gitlab.pik-potsdam.de:cxesmc/climber-x-input.git input # Prepare your configuration script cd config cp pik_hpc2024_ifx myhost_mycompiler # use pik_hpc2024_ifx as template # Modify the file `myhost_mycompiler` to match your paths. cd .. # Run configuration script python config.py config/pik_ifort ### Download and configure additional libraries ### # fftw cd src/utils/ wget https://www.fftw.org/fftw-3.3.10.tar.gz tar -xvf fftw-3.3.10.tar.gz rm fftw-3.3.10.tar.gz mv fftw-3.3.10 fftw cd fftw ./configure --prefix=$PWD --enable-openmp CC=icc F77=ifort make make install cd .. # coordinates cd src/utils/ git clone git@github.com:cxesmc/coordinates.git cd coordinates python config.py config/pik_ifort cd ../../.. # Return to climber-x parent directory ### Compile and run ### # Compile the climate model make cleanall make climber-clim # Run a pre-industrial equilibrium climate-only test simulation ./job_climber -s -o output/clim If you would also like to run CLIMBER-X with an interactive carbon cycle, then the HAMOCC ocean biogeochemistry ( bgc ) code must also be downloaded: # bgc cd src/ git clone git@github.com:cxesmc/bgc.git cd .. Since the HAMOCC model source code is not open source, the bgc repository is private at the moment and you need to be given permission in order to access it. HAMOCC is covered by the Max Planck Institute for Meteorology software licence agreement as part of the MPI-ESM ( https://code.mpimet.mpg.de/attachments/download/26986/MPI-ESM_SLA_v3.4.pdf ). A pre-requisite to access the bgc repository is therefore that you agree to the MPI-ESM license by following the steps outlined here: https://code.mpimet.mpg.de/projects/mpi-esm-license . Once you have done so, send an email to matteo.willeit@gmail.com and you will be granted permission to access the bgc repository. Note that you will need a GitHub account for that. # Compile the climate and carbon cycle model make clean make climber-clim-bgc # Run a pre-industrial equilibrium simulation with ocean biogeochemistry ./job_climber -s -o output/clim-bgc \\&control=\"flag_bgc=T\" If you would also like to run with an interactive ice sheet, then the lis library must be installed, the Yelmo ice-sheet code must be downloaded and configured and the solid Earth model VILMA libraries must be downloaded before compiling: # lis cd src/utils git clone git@github.com:anishida/lis.git lis-2.1.5 cd lis-2.1.5 ./configure --prefix=$PWD/../lis --enable-omp --enable-f90 CC=icc FC=ifort make make install cd .. # yelmo cd src git clone git@github.com:palma-ice/yelmo.git cd yelmo git checkout climber-x # Get climber-x branch python config.py config/pik_ifort cd ../.. # vilma cd src/ git clone git@github.com:cxesmc/vilma.git # private repository, premission needed cd .. Since the VILMA model code is not open source, the vilma repository is private at the moment and you need to be given permission in order to access it. Please send an email to Matteo Willeit and Volker Klemann and you will be granted permission to access the vilma repository. # Compile the climate and ice sheet model make clean make climber-clim-ice # Run pre-industrial equilibrium simulation with interactive Greenland ice sheet ./job_climber -s -o output/clim-ice \\&control=\"flag_ice=T flag_geo=T flag_smb=T flag_imo=T ice_model_name=yelmo ice_domain_name=GRL-16KM\" If you have followed all steps above you will also be ready to run fully coupled simulations: # Compile the fully coupled model make clean make climber-clim-bgc-ice # or equivalently: make climber # Run pre-industrial equilibrium simulation with ocean biogeochemistry and interactive Greenland ice sheet ./job_climber -s -o output/clim-bgc-ice \\&control=\"flag_bgc=T flag_ice=T flag_geo=T flag_smb=T flag_imo=T ice_model_name=yelmo ice_domain_name=GRL-16KM\" Directory structure config/ Configuration files for compilation on different systems. input/ Location of any input data needed by the model. output/ Default location for model output. maps/ Location of the maps that will be generated to map/interpolate between different grids. nml/ Default parameter namelists that manage the model configuration. restart/ Location of the restart files needed to continue previous model simulations. src/ Source code for CLIMBER-X. Usage Follow the steps below to (1) obtain the code, (2) configure the Makefile for your system, (3) compile an executable program and (4) run a test simulation. 1. Get the code Clone the repository from https://github.com/cxesmc/climber-x : # Clone code repository git clone https://github.com/cxesmc/climber-x.git git clone git@github.com:cxesmc/climber-x.git # via ssh cd climber-x # Clone input file directory git clone git@gitlab.pik-potsdam.de:cxesmc/climber-x-input.git input If you plan to make changes to the code, it is wise to check out a new branch: git checkout -b user-dev You should now be working on the branch user-dev . 2. Create the system-specific Makefile To compile CLIMBER-X , you need to generate a Makefile that is appropriate for your system. In the folder config , you need to specify a configuration file that defines the compiler and flags, including definition of the paths to the NetCDF , FFTW , coordinates , Yelmo and LIS libraries. Note that it can be convenient to install FFTW , coordinates , Yelmo and LIS as subdirectories of the src/ folder, to be sure they are compiled consistently with CLIMBER-X . You can use another configuration file in the config folder as a template, e.g., cd config cp pik_ifort myhost_mycompiler Then you would modify the file myhost_mycompiler to match your paths. Back in climber-x , you can then generate your Makefile with the provided python configuration script: cd ../climber-x python config.py config/myhost_mycompiler The result should be a Makefile that is ready for use. 3. Compiling CLIMBER-X Assuming the source has been downloaded and configured, and all dependencies have also been compiled, now you are ready to compile CLIMBER-X : make clean make climber-clim There are currently four different flavors of CLIMBER-X that can be compiled: climber-clim : minimal climate configuration with atmosphere, ocean, sea ice and land climber-clim-bgc : clim plus with ocean biogeochemistry climber-clim-ice : clim plus with ice sheets climber-clim-bgc-ice : clim plus with ocean biogeochemistry and ice sheets These can be compiled by calling the individual names, e.g. make climber-clim or make climber-clim-bgc-ice . By default, it is also possible to call make climber as a shorter alias for make climber-clim-bgc-ice . The climate only version climber-clim corresponds to the version described by Willeit et al. (2022). This particular model setup does not require non-climate source code or the LIS library for compilation. That's it. The executable climber.x should now be available in the main directory. To compile the model with debug flags enabled use: make climber debug=1 By default, the model is compiled with openmp . To compile the model without openmp use: make climber openmp=0 This version should typically not be used. 4. Running CLIMBER-X After CLIMBER-X has been compiled, several steps must be completed to run the executable climber.x : Create a run directory ( RUNDIR ). Copy namelist parameter files to RUNDIR . Make links to the input , maps and restart directories in RUNDIR . Copy VILMA restart files to RUNDIR (since these are eventually modified by climber.x ). Copy the executable file climber.x to RUNDIR . To run on the cluster, create a job submission script (e.g. job.submit ) in RUNDIR to manage various computing options (number of processors, etc). When these steps are completed, climber.x should be run directly from RUNDIR using the job submission script. E.g., using SLURM: cd RUNDIR sbatch job.submit If not using the cluster, CLIMBER-X can also be run manually by entering the RUNDIR and specifying the current directory as an argument: cd RUNDIR ./climber.x ./ > out.out Either of the above will run climber in RUNDIR with all simulation output stored in the same directory. Because the directory includes the executable and is self-contained, assuming the contents of the linked directories do not change, the simulation can be re-run at any time. To perform all of the above steps manually for multiple simulations is very tedious and time-consuming, so a \"job\" script has been created to handle the process. Currently two job-script methods are available ( job_climber and runcx ), which are described in the sections below. Using job_climber Aside from possible options, job_climber is always called with the required argument -o RUNDIR that specifies the output directory. So, to run a climber.x simulation as a job on the cluster in RUNDIR , run the command: ./job_climber -s -o RUNDIR where RUNDIR is the desired run directory. The option -s specifies that the job should be run on the cluster. Alternatively, use -r instead of -s to simply run it as a background process. Other options include -c for the queue name (short, priority, etc), -w for the maximum wall clock time to allow in hours, -j to specify whether a serial or parallel job is desired (serial or parallel), -n to specify the number of processors, and others. Using runcx Unlike job_climber , the newer script runcx was designed only to handle running one simulation, while leaving the task of ensemble generation to the Python module runner , developed for that task. See ./runcx -h for details on possible arguments. Aside from possible options, runcx is always called with the required argument -o RUNDIR that specifies the output directory. So, to run a climber.x simulation as a job on the cluster in RUNDIR , run the command: ./runcx -s -o RUNDIR where RUNDIR is the desired run directory. The option -s specifies that the job should be run on the cluster. Alternatively, use -r instead of -s to simply run it as a background process. Other options include -q, --qos for the queue name (short, priority, etc), -w, --wall for the maximum wall clock time to allow in hours, --part to name the processor partition (haswell, broadwell, etc), --omp to specify the number of processors, and others. See ./runcx -h for all options. Note that various default options can be specified in the script's json-format configuration file runcx.js , so as to avoid having to specifying them every time. Run as a command as above, this script will run a simulation using the parameters as they are specified in the namelist parameter files in the nml directory. In addition, it is possible to modify the parameters of one simulation at the command line using the argument -p KEY=VAL KEY=VAL ... . So, for example, the following command: ./runcx -s -o RUNDIR -p ctl.n_accel=10 will run climber.x on the cluster in the output directory RUNDIR with the control parameter control.n_accel set to 10 . Note that ctl is a convenient alias for the namelist group control , as defined in runcx.js . To perform a simulation an ensemble of simulations with modified parameter values, runcx should be called via jobrun (see below). Using jobrun with runcx jobrun is a command that is part of the Python runner library, found here: https://github.com/alex-robinson/runner . This command facilitates running ensembles of simulations, or simulations with modified parameters via a convenient command-line interface. See the above runner page for its installation instructions. using jobrun , the following command would produce the same simulation as ./runcx -s RUNDIR : jobrun ./runcx -s -- -o OUTDIR The difference here is that all options that follow the -- are jobrun options. So now we don't specify the specific RUNDIR , but rather an encapsulating OUTDIR that will contain one or many RUNDIR 's. In the above example, no parameters are changed, so the simulation is saved in the default directory: OUTDIR/default . If we want to change a parameter, this can be done as with the runcx script via the -p option: jobrun ./runcx -s -- -o OUTDIR -p ctl.n_accel=10 This will produce one simulation with the parameter control.n_accel=10 . Since we have changed a parameter for this simulation, jobrun treats this as an ensemble, so the output is saved in OUTDIR/0 for simulation 0. In short, the above command is equivalent to ./runcx -s -o OUTDIR -p ctl.n_accel=10 , but in the former case, the output is stored in OUTDIR/0 and in the latter case, it is stored directly in OUTDIR . The power of jobrun comes when we want to run an ensemble: jobrun ./runcx -s -- -o OUTDIR -p ctl.n_accel=1,5,10 This ensemble of simulations will appear in OUTDIR/0 , OUTDIR/1 and OUTDIR/2 , respectively. A more informative output directory can be made using the option -a along with -o : jobrun ./runcx -s -- -a -o OUTDIR -p ctl.n_accel=1,5,10 In this case, the run directories are OUTDIR/ctl.nccl.1 , OUTDIR/ctl.nccl.5 and OUTDIR/ctl.nccl.10 , respectively. General information about the ensemble can be found in the main ensemble directory OUTDIR : params.txt : contains a table of the parameter combinations set on the command line (can be used to run a new ensemble). info.txt : the same parameter table as params.txt , but also including an index of the runid (0,1,2, etc) and the RUNDIR : info.txt : runid ctl.n_accel rundir 0 1 ctl.nccl.1 1 5 ctl.nccl.5 2 10 ctl.nccl.10 It is of course possible to define multiple parameter permutations: jobrun ./runcx -s -- -o OUTDIR -p ctl.n_accel=1,5,10 smb.alb_ice=0.3,0.4 To generate a more complex ensemble, using e.g. Latin-Hypercube sampling, then a two step approach is often better. First, use the runner command job sample to build the ensemble, then use jobrun to run it: # Generate ensemble parameters job sample -o lhs.txt --seed 4 -N 100 atm.c_trop_2=0.8,1.2 smb.alb_ice=0.3,0.4 # Run ensemble jobrun ./runcx -s -- -o OUTDIR -i lhs.txt This two-step method facilitates checking that the ensemble was generated properly and improves reproducibility, since the exact parameter values are available in the table. 5. Test simulation A simple climate-only test simulation for pre-industrial conditions can be run as: ./job_climber -s -f -o OUTDIR","title":"Getting started"},{"location":"getting-started/#getting-started","text":"Here you can find the basic information and steps needed to get CLIMBER-X running. Some step-by-step commands are given for specific environments. To see how to install CLIMBER-X on the HPC2024 cluster at PIK, see: Running-at-PIK for detailed instructions. There are currently four different flavors of CLIMBER-X that can be set up: climber-clim : minimal climate model configuration with atmosphere, ocean, sea ice and land (including dynamic vegetation) climber-clim-bgc : coupled climate-carbon cycle model configuration; clim plus with ocean biogeochemistry climber-clim-ice : coupled climate-ice sheet model configuration; clim plus with ice sheets climber-clim-bgc-ice : fully coupled model configuration; clim plus with ocean biogeochemistry and ice sheets The model dependencies vary according to the desired model configuration: Dependencies are: NetCDF, FFTW, coordinates Additional dependencies if using coupled ice sheets are: Yelmo, LIS Optional dependencies are: CDO, runner See: Dependencies for more details.","title":"Getting started"},{"location":"getting-started/#super-quick-start","text":"A summary of example commands to get started is given below using the ifort compiler. For more detailed information see subsequent sections. ### Download the CLIMBER-X code ### # Clone code repository git clone git@github.com:cxesmc/climber-x.git # Enter directory cd climber-x # Clone input file directory git clone git@gitlab.pik-potsdam.de:cxesmc/climber-x-input.git input # Prepare your configuration script cd config cp pik_hpc2024_ifx myhost_mycompiler # use pik_hpc2024_ifx as template # Modify the file `myhost_mycompiler` to match your paths. cd .. # Run configuration script python config.py config/pik_ifort ### Download and configure additional libraries ### # fftw cd src/utils/ wget https://www.fftw.org/fftw-3.3.10.tar.gz tar -xvf fftw-3.3.10.tar.gz rm fftw-3.3.10.tar.gz mv fftw-3.3.10 fftw cd fftw ./configure --prefix=$PWD --enable-openmp CC=icc F77=ifort make make install cd .. # coordinates cd src/utils/ git clone git@github.com:cxesmc/coordinates.git cd coordinates python config.py config/pik_ifort cd ../../.. # Return to climber-x parent directory ### Compile and run ### # Compile the climate model make cleanall make climber-clim # Run a pre-industrial equilibrium climate-only test simulation ./job_climber -s -o output/clim If you would also like to run CLIMBER-X with an interactive carbon cycle, then the HAMOCC ocean biogeochemistry ( bgc ) code must also be downloaded: # bgc cd src/ git clone git@github.com:cxesmc/bgc.git cd .. Since the HAMOCC model source code is not open source, the bgc repository is private at the moment and you need to be given permission in order to access it. HAMOCC is covered by the Max Planck Institute for Meteorology software licence agreement as part of the MPI-ESM ( https://code.mpimet.mpg.de/attachments/download/26986/MPI-ESM_SLA_v3.4.pdf ). A pre-requisite to access the bgc repository is therefore that you agree to the MPI-ESM license by following the steps outlined here: https://code.mpimet.mpg.de/projects/mpi-esm-license . Once you have done so, send an email to matteo.willeit@gmail.com and you will be granted permission to access the bgc repository. Note that you will need a GitHub account for that. # Compile the climate and carbon cycle model make clean make climber-clim-bgc # Run a pre-industrial equilibrium simulation with ocean biogeochemistry ./job_climber -s -o output/clim-bgc \\&control=\"flag_bgc=T\" If you would also like to run with an interactive ice sheet, then the lis library must be installed, the Yelmo ice-sheet code must be downloaded and configured and the solid Earth model VILMA libraries must be downloaded before compiling: # lis cd src/utils git clone git@github.com:anishida/lis.git lis-2.1.5 cd lis-2.1.5 ./configure --prefix=$PWD/../lis --enable-omp --enable-f90 CC=icc FC=ifort make make install cd .. # yelmo cd src git clone git@github.com:palma-ice/yelmo.git cd yelmo git checkout climber-x # Get climber-x branch python config.py config/pik_ifort cd ../.. # vilma cd src/ git clone git@github.com:cxesmc/vilma.git # private repository, premission needed cd .. Since the VILMA model code is not open source, the vilma repository is private at the moment and you need to be given permission in order to access it. Please send an email to Matteo Willeit and Volker Klemann and you will be granted permission to access the vilma repository. # Compile the climate and ice sheet model make clean make climber-clim-ice # Run pre-industrial equilibrium simulation with interactive Greenland ice sheet ./job_climber -s -o output/clim-ice \\&control=\"flag_ice=T flag_geo=T flag_smb=T flag_imo=T ice_model_name=yelmo ice_domain_name=GRL-16KM\" If you have followed all steps above you will also be ready to run fully coupled simulations: # Compile the fully coupled model make clean make climber-clim-bgc-ice # or equivalently: make climber # Run pre-industrial equilibrium simulation with ocean biogeochemistry and interactive Greenland ice sheet ./job_climber -s -o output/clim-bgc-ice \\&control=\"flag_bgc=T flag_ice=T flag_geo=T flag_smb=T flag_imo=T ice_model_name=yelmo ice_domain_name=GRL-16KM\"","title":"Super-quick start"},{"location":"getting-started/#directory-structure","text":"config/ Configuration files for compilation on different systems. input/ Location of any input data needed by the model. output/ Default location for model output. maps/ Location of the maps that will be generated to map/interpolate between different grids. nml/ Default parameter namelists that manage the model configuration. restart/ Location of the restart files needed to continue previous model simulations. src/ Source code for CLIMBER-X.","title":"Directory structure"},{"location":"getting-started/#usage","text":"Follow the steps below to (1) obtain the code, (2) configure the Makefile for your system, (3) compile an executable program and (4) run a test simulation.","title":"Usage"},{"location":"getting-started/#1-get-the-code","text":"Clone the repository from https://github.com/cxesmc/climber-x : # Clone code repository git clone https://github.com/cxesmc/climber-x.git git clone git@github.com:cxesmc/climber-x.git # via ssh cd climber-x # Clone input file directory git clone git@gitlab.pik-potsdam.de:cxesmc/climber-x-input.git input If you plan to make changes to the code, it is wise to check out a new branch: git checkout -b user-dev You should now be working on the branch user-dev .","title":"1. Get the code"},{"location":"getting-started/#2-create-the-system-specific-makefile","text":"To compile CLIMBER-X , you need to generate a Makefile that is appropriate for your system. In the folder config , you need to specify a configuration file that defines the compiler and flags, including definition of the paths to the NetCDF , FFTW , coordinates , Yelmo and LIS libraries. Note that it can be convenient to install FFTW , coordinates , Yelmo and LIS as subdirectories of the src/ folder, to be sure they are compiled consistently with CLIMBER-X . You can use another configuration file in the config folder as a template, e.g., cd config cp pik_ifort myhost_mycompiler Then you would modify the file myhost_mycompiler to match your paths. Back in climber-x , you can then generate your Makefile with the provided python configuration script: cd ../climber-x python config.py config/myhost_mycompiler The result should be a Makefile that is ready for use.","title":"2. Create the system-specific Makefile"},{"location":"getting-started/#3-compiling-climber-x","text":"Assuming the source has been downloaded and configured, and all dependencies have also been compiled, now you are ready to compile CLIMBER-X : make clean make climber-clim There are currently four different flavors of CLIMBER-X that can be compiled: climber-clim : minimal climate configuration with atmosphere, ocean, sea ice and land climber-clim-bgc : clim plus with ocean biogeochemistry climber-clim-ice : clim plus with ice sheets climber-clim-bgc-ice : clim plus with ocean biogeochemistry and ice sheets These can be compiled by calling the individual names, e.g. make climber-clim or make climber-clim-bgc-ice . By default, it is also possible to call make climber as a shorter alias for make climber-clim-bgc-ice . The climate only version climber-clim corresponds to the version described by Willeit et al. (2022). This particular model setup does not require non-climate source code or the LIS library for compilation. That's it. The executable climber.x should now be available in the main directory. To compile the model with debug flags enabled use: make climber debug=1 By default, the model is compiled with openmp . To compile the model without openmp use: make climber openmp=0 This version should typically not be used.","title":"3. Compiling CLIMBER-X"},{"location":"getting-started/#4-running-climber-x","text":"After CLIMBER-X has been compiled, several steps must be completed to run the executable climber.x : Create a run directory ( RUNDIR ). Copy namelist parameter files to RUNDIR . Make links to the input , maps and restart directories in RUNDIR . Copy VILMA restart files to RUNDIR (since these are eventually modified by climber.x ). Copy the executable file climber.x to RUNDIR . To run on the cluster, create a job submission script (e.g. job.submit ) in RUNDIR to manage various computing options (number of processors, etc). When these steps are completed, climber.x should be run directly from RUNDIR using the job submission script. E.g., using SLURM: cd RUNDIR sbatch job.submit If not using the cluster, CLIMBER-X can also be run manually by entering the RUNDIR and specifying the current directory as an argument: cd RUNDIR ./climber.x ./ > out.out Either of the above will run climber in RUNDIR with all simulation output stored in the same directory. Because the directory includes the executable and is self-contained, assuming the contents of the linked directories do not change, the simulation can be re-run at any time. To perform all of the above steps manually for multiple simulations is very tedious and time-consuming, so a \"job\" script has been created to handle the process. Currently two job-script methods are available ( job_climber and runcx ), which are described in the sections below.","title":"4. Running CLIMBER-X"},{"location":"getting-started/#using-job_climber","text":"Aside from possible options, job_climber is always called with the required argument -o RUNDIR that specifies the output directory. So, to run a climber.x simulation as a job on the cluster in RUNDIR , run the command: ./job_climber -s -o RUNDIR where RUNDIR is the desired run directory. The option -s specifies that the job should be run on the cluster. Alternatively, use -r instead of -s to simply run it as a background process. Other options include -c for the queue name (short, priority, etc), -w for the maximum wall clock time to allow in hours, -j to specify whether a serial or parallel job is desired (serial or parallel), -n to specify the number of processors, and others.","title":"Using job_climber"},{"location":"getting-started/#using-runcx","text":"Unlike job_climber , the newer script runcx was designed only to handle running one simulation, while leaving the task of ensemble generation to the Python module runner , developed for that task. See ./runcx -h for details on possible arguments. Aside from possible options, runcx is always called with the required argument -o RUNDIR that specifies the output directory. So, to run a climber.x simulation as a job on the cluster in RUNDIR , run the command: ./runcx -s -o RUNDIR where RUNDIR is the desired run directory. The option -s specifies that the job should be run on the cluster. Alternatively, use -r instead of -s to simply run it as a background process. Other options include -q, --qos for the queue name (short, priority, etc), -w, --wall for the maximum wall clock time to allow in hours, --part to name the processor partition (haswell, broadwell, etc), --omp to specify the number of processors, and others. See ./runcx -h for all options. Note that various default options can be specified in the script's json-format configuration file runcx.js , so as to avoid having to specifying them every time. Run as a command as above, this script will run a simulation using the parameters as they are specified in the namelist parameter files in the nml directory. In addition, it is possible to modify the parameters of one simulation at the command line using the argument -p KEY=VAL KEY=VAL ... . So, for example, the following command: ./runcx -s -o RUNDIR -p ctl.n_accel=10 will run climber.x on the cluster in the output directory RUNDIR with the control parameter control.n_accel set to 10 . Note that ctl is a convenient alias for the namelist group control , as defined in runcx.js . To perform a simulation an ensemble of simulations with modified parameter values, runcx should be called via jobrun (see below).","title":"Using runcx"},{"location":"getting-started/#using-jobrun-with-runcx","text":"jobrun is a command that is part of the Python runner library, found here: https://github.com/alex-robinson/runner . This command facilitates running ensembles of simulations, or simulations with modified parameters via a convenient command-line interface. See the above runner page for its installation instructions. using jobrun , the following command would produce the same simulation as ./runcx -s RUNDIR : jobrun ./runcx -s -- -o OUTDIR The difference here is that all options that follow the -- are jobrun options. So now we don't specify the specific RUNDIR , but rather an encapsulating OUTDIR that will contain one or many RUNDIR 's. In the above example, no parameters are changed, so the simulation is saved in the default directory: OUTDIR/default . If we want to change a parameter, this can be done as with the runcx script via the -p option: jobrun ./runcx -s -- -o OUTDIR -p ctl.n_accel=10 This will produce one simulation with the parameter control.n_accel=10 . Since we have changed a parameter for this simulation, jobrun treats this as an ensemble, so the output is saved in OUTDIR/0 for simulation 0. In short, the above command is equivalent to ./runcx -s -o OUTDIR -p ctl.n_accel=10 , but in the former case, the output is stored in OUTDIR/0 and in the latter case, it is stored directly in OUTDIR . The power of jobrun comes when we want to run an ensemble: jobrun ./runcx -s -- -o OUTDIR -p ctl.n_accel=1,5,10 This ensemble of simulations will appear in OUTDIR/0 , OUTDIR/1 and OUTDIR/2 , respectively. A more informative output directory can be made using the option -a along with -o : jobrun ./runcx -s -- -a -o OUTDIR -p ctl.n_accel=1,5,10 In this case, the run directories are OUTDIR/ctl.nccl.1 , OUTDIR/ctl.nccl.5 and OUTDIR/ctl.nccl.10 , respectively. General information about the ensemble can be found in the main ensemble directory OUTDIR : params.txt : contains a table of the parameter combinations set on the command line (can be used to run a new ensemble). info.txt : the same parameter table as params.txt , but also including an index of the runid (0,1,2, etc) and the RUNDIR : info.txt : runid ctl.n_accel rundir 0 1 ctl.nccl.1 1 5 ctl.nccl.5 2 10 ctl.nccl.10 It is of course possible to define multiple parameter permutations: jobrun ./runcx -s -- -o OUTDIR -p ctl.n_accel=1,5,10 smb.alb_ice=0.3,0.4 To generate a more complex ensemble, using e.g. Latin-Hypercube sampling, then a two step approach is often better. First, use the runner command job sample to build the ensemble, then use jobrun to run it: # Generate ensemble parameters job sample -o lhs.txt --seed 4 -N 100 atm.c_trop_2=0.8,1.2 smb.alb_ice=0.3,0.4 # Run ensemble jobrun ./runcx -s -- -o OUTDIR -i lhs.txt This two-step method facilitates checking that the ensemble was generated properly and improves reproducibility, since the exact parameter values are available in the table.","title":"Using jobrun with runcx"},{"location":"getting-started/#5-test-simulation","text":"A simple climate-only test simulation for pre-industrial conditions can be run as: ./job_climber -s -f -o OUTDIR","title":"5. Test simulation"},{"location":"running-at-awi/","text":"Running CLIMBER-X on the albedo cluster at AWI To run CLIMBER-X on the albedo cluster at AWI, essentially the same instructions apply as for running at PIK . The only differences are the following: A different set of modules needed to be loaded into the environment to get the right compilers and NetCDF libraries etc. installed. For albedo use the following: module load intel-oneapi-compilers/2022.1.0 module load netcdf-c/4.8.1-openmpi4.1.3-oneapi2022.1.0 module load netcdf-fortran/4.5.4-oneapi2022.1.0 module load udunits/2.2.28 module load ncview/2.1.8 module load cdo/2.2.0 module load python/3.10.4 When installing the climber-x-exlib libraries, use the dkrz specific script: cd climber-x-exlib ./install_dkrz.sh ifx All other instructions should be the same.","title":"Running at AWI"},{"location":"running-at-awi/#running-climber-x-on-the-albedo-cluster-at-awi","text":"To run CLIMBER-X on the albedo cluster at AWI, essentially the same instructions apply as for running at PIK . The only differences are the following: A different set of modules needed to be loaded into the environment to get the right compilers and NetCDF libraries etc. installed. For albedo use the following: module load intel-oneapi-compilers/2022.1.0 module load netcdf-c/4.8.1-openmpi4.1.3-oneapi2022.1.0 module load netcdf-fortran/4.5.4-oneapi2022.1.0 module load udunits/2.2.28 module load ncview/2.1.8 module load cdo/2.2.0 module load python/3.10.4 When installing the climber-x-exlib libraries, use the dkrz specific script: cd climber-x-exlib ./install_dkrz.sh ifx All other instructions should be the same.","title":"Running CLIMBER-X on the albedo cluster at AWI"},{"location":"running-at-pik/","text":"Running CLIMBER-X on the HPC2024 (FOOTE) at PIK Here you can find the basic information and steps needed to get CLIMBER-X running on the HPC2024 (FOOTE) at PIK. Loading required modules The following modules have to be loaded in order to compile and run the model. For convenience you can also add those commands to your .profile file in your home directory. module purge module use /p/system/modulefiles/compiler \\ /p/system/modulefiles/gpu \\ /p/system/modulefiles/libraries \\ /p/system/modulefiles/parallel \\ /p/system/modulefiles/tools module load intel/oneAPI/2024.0.0 module load netcdf-c/4.9.2 module load netcdf-fortran-intel/4.6.1 module load udunits/2.2.28 module load ncview/2.1.10 module load cdo/2.4.2 Get the code CLIMBER-X climate model ### Download the CLIMBER-X code ### # Clone repository git clone git@github.com:cxesmc/climber-x.git # Enter directory cd climber-x # Run configuration script python3 config.py config/pik_hpc2024_ifx # Clone input file directory git clone git@gitlab.pik-potsdam.de:cxesmc/climber-x-input.git input # Step back and clone and install external libraries repository cd .. git clone git@github.com:cxesmc/climber-x-exlib.git cd climber-x-exlib ./install_pik.sh ifx EXLIBSRC=$PWD cd ../climber-x/src/utils/ ln -s $EXLIBSRC/exlib ./ cd ../.. # Return to climber-x parent directory # Download and configure coordinates cd src/utils/ git clone git@github.com:cxesmc/coordinates.git cd coordinates python3 config.py config/pik_hpc2024_ifx cd ../../.. # Return to climber-x parent directory ### Compile and run ### # Compile the climate model make cleanall make climber-clim # Run a pre-industrial equilibrium climate-only test simulation ./job_climber -s -f -o output/clim -c short -j parallel -n 16 CLIMBER-X climate and carbon cycle model If you would also like to run CLIMBER-X with an interactive carbon cycle, then the HAMOCC ocean biogeochemistry ( bgc ) code must also be downloaded: # bgc cd src/ git clone git@github.com:cxesmc/bgc.git cd .. Since the HAMOCC model code is not open source, the bgc repository is private at the moment and you need to be given permission in order to access it. HAMOCC is covered by the Max Planck Institute for Meteorology software licence agreement as part of the MPI-ESM ( https://code.mpimet.mpg.de/attachments/download/26986/MPI-ESM_SLA_v3.4.pdf ). A pre-requisite to access the bgc repository is therefore that you agree to the MPI-ESM license by following the steps outlined here: https://code.mpimet.mpg.de/projects/mpi-esm-license . Once you have done so, send an email to Matteo Willeit and you will be granted permission to access the bgc repository. # Compile the climate and carbon cycle model make clean make climber-clim-bgc # Run a pre-industrial equilibrium simulation with ocean biogeochemistry ./job_climber -s -f -o output/clim-bgc -c short -j parallel -n 16 \\&control=\"flag_bgc=T\" CLIMBER-X climate and ice sheet model If you would also like to run with an interactive ice sheet, the Yelmo ice-sheet code must be downloaded and configured and the solid Earth model VILMA libraries must be downloaded before compiling: # yelmo cd src git clone git@github.com:palma-ice/yelmo.git cd yelmo git checkout climber-x # Get climber-x branch python3 config.py config/pik_hpc2024_ifx cd ../.. # vilma cd src/ git clone git@github.com:cxesmc/vilma.git # private repository, premission needed cd .. Since the VILMA model code is not open source, the vilma repository is private at the moment and you need to be given permission in order to access it. Please send an email to Matteo Willeit and Volker Klemann and you will be granted permission to access the vilma repository. # Compile the climate and ice sheet model make clean make climber-clim-ice # Run pre-industrial equilibrium simulation with interactive Greenland ice sheet ./job_climber -s -f -o output/clim-ice -c short -j parallel -n 16 \\&control=\"flag_ice=T flag_geo=T flag_smb=T flag_imo=T ice_model_name=yelmo ice_domain_name=GRL-16KM\" Fully coupled CLIMBER-X configuration If you have followed all steps above you will also be ready to run fully coupled simulations: # Compile the fully coupled model make clean make climber-clim-bgc-ice # or equivalently make climber # Run pre-industrial equilibrium simulation with ocean biogeochemistry and interactive Greenland ice sheet ./job_climber -s -f -o output/clim-bgc-ice -c short -j parallel -n 16 \\&control=\"flag_bgc=T flag_ice=T flag_geo=T flag_smb=T flag_imo=T ice_model_name=yelmo ice_domain_name=GRL-16KM\"","title":"Running at PIK"},{"location":"running-at-pik/#running-climber-x-on-the-hpc2024-foote-at-pik","text":"Here you can find the basic information and steps needed to get CLIMBER-X running on the HPC2024 (FOOTE) at PIK.","title":"Running CLIMBER-X on the HPC2024 (FOOTE) at PIK"},{"location":"running-at-pik/#loading-required-modules","text":"The following modules have to be loaded in order to compile and run the model. For convenience you can also add those commands to your .profile file in your home directory. module purge module use /p/system/modulefiles/compiler \\ /p/system/modulefiles/gpu \\ /p/system/modulefiles/libraries \\ /p/system/modulefiles/parallel \\ /p/system/modulefiles/tools module load intel/oneAPI/2024.0.0 module load netcdf-c/4.9.2 module load netcdf-fortran-intel/4.6.1 module load udunits/2.2.28 module load ncview/2.1.10 module load cdo/2.4.2","title":"Loading required modules"},{"location":"running-at-pik/#get-the-code","text":"","title":"Get the code"},{"location":"running-at-pik/#climber-x-climate-model","text":"### Download the CLIMBER-X code ### # Clone repository git clone git@github.com:cxesmc/climber-x.git # Enter directory cd climber-x # Run configuration script python3 config.py config/pik_hpc2024_ifx # Clone input file directory git clone git@gitlab.pik-potsdam.de:cxesmc/climber-x-input.git input # Step back and clone and install external libraries repository cd .. git clone git@github.com:cxesmc/climber-x-exlib.git cd climber-x-exlib ./install_pik.sh ifx EXLIBSRC=$PWD cd ../climber-x/src/utils/ ln -s $EXLIBSRC/exlib ./ cd ../.. # Return to climber-x parent directory # Download and configure coordinates cd src/utils/ git clone git@github.com:cxesmc/coordinates.git cd coordinates python3 config.py config/pik_hpc2024_ifx cd ../../.. # Return to climber-x parent directory ### Compile and run ### # Compile the climate model make cleanall make climber-clim # Run a pre-industrial equilibrium climate-only test simulation ./job_climber -s -f -o output/clim -c short -j parallel -n 16","title":"CLIMBER-X climate model"},{"location":"running-at-pik/#climber-x-climate-and-carbon-cycle-model","text":"If you would also like to run CLIMBER-X with an interactive carbon cycle, then the HAMOCC ocean biogeochemistry ( bgc ) code must also be downloaded: # bgc cd src/ git clone git@github.com:cxesmc/bgc.git cd .. Since the HAMOCC model code is not open source, the bgc repository is private at the moment and you need to be given permission in order to access it. HAMOCC is covered by the Max Planck Institute for Meteorology software licence agreement as part of the MPI-ESM ( https://code.mpimet.mpg.de/attachments/download/26986/MPI-ESM_SLA_v3.4.pdf ). A pre-requisite to access the bgc repository is therefore that you agree to the MPI-ESM license by following the steps outlined here: https://code.mpimet.mpg.de/projects/mpi-esm-license . Once you have done so, send an email to Matteo Willeit and you will be granted permission to access the bgc repository. # Compile the climate and carbon cycle model make clean make climber-clim-bgc # Run a pre-industrial equilibrium simulation with ocean biogeochemistry ./job_climber -s -f -o output/clim-bgc -c short -j parallel -n 16 \\&control=\"flag_bgc=T\"","title":"CLIMBER-X climate and carbon cycle model"},{"location":"running-at-pik/#climber-x-climate-and-ice-sheet-model","text":"If you would also like to run with an interactive ice sheet, the Yelmo ice-sheet code must be downloaded and configured and the solid Earth model VILMA libraries must be downloaded before compiling: # yelmo cd src git clone git@github.com:palma-ice/yelmo.git cd yelmo git checkout climber-x # Get climber-x branch python3 config.py config/pik_hpc2024_ifx cd ../.. # vilma cd src/ git clone git@github.com:cxesmc/vilma.git # private repository, premission needed cd .. Since the VILMA model code is not open source, the vilma repository is private at the moment and you need to be given permission in order to access it. Please send an email to Matteo Willeit and Volker Klemann and you will be granted permission to access the vilma repository. # Compile the climate and ice sheet model make clean make climber-clim-ice # Run pre-industrial equilibrium simulation with interactive Greenland ice sheet ./job_climber -s -f -o output/clim-ice -c short -j parallel -n 16 \\&control=\"flag_ice=T flag_geo=T flag_smb=T flag_imo=T ice_model_name=yelmo ice_domain_name=GRL-16KM\"","title":"CLIMBER-X climate and ice sheet model"},{"location":"running-at-pik/#fully-coupled-climber-x-configuration","text":"If you have followed all steps above you will also be ready to run fully coupled simulations: # Compile the fully coupled model make clean make climber-clim-bgc-ice # or equivalently make climber # Run pre-industrial equilibrium simulation with ocean biogeochemistry and interactive Greenland ice sheet ./job_climber -s -f -o output/clim-bgc-ice -c short -j parallel -n 16 \\&control=\"flag_bgc=T flag_ice=T flag_geo=T flag_smb=T flag_imo=T ice_model_name=yelmo ice_domain_name=GRL-16KM\"","title":"Fully coupled CLIMBER-X configuration"},{"location":"running-at-pik_old/","text":"Running CLIMBER-X on the HPC2015 at PIK Here you can find the basic information and steps needed to get CLIMBER-X running on the (old) HPC2015 at PIK. Get the code CLIMBER-X climate model ### Download the CLIMBER-X code ### # Clone repository git clone git@github.com:cxesmc/climber-x.git # Enter directory cd climber-x # Clone input file directory git clone git@gitlab.pik-potsdam.de:cxesmc/climber-x-input.git input # Run configuration script python config.py config/pik_ifort ### Download and configure additional libraries ### # fftw cd src/utils/ wget https://www.fftw.org/fftw-3.3.10.tar.gz tar -xvf fftw-3.3.10.tar.gz rm fftw-3.3.10.tar.gz mv fftw-3.3.10 fftw cd fftw ./configure --prefix=$PWD --enable-openmp CC=icc F77=ifort make make install cd ../../.. # Return to climber-x parent directory # coordinates cd src/utils/ git clone git@github.com:cxesmc/coordinates.git cd coordinates python config.py config/pik_ifort cd ../../.. # Return to climber-x parent directory ### Compile and run ### # Compile the climate model make cleanall make climber-clim # Run a pre-industrial equilibrium climate-only test simulation ./job_climber -s -f -o output/clim -c short -j parallel -n 16 CLIMBER-X climate and carbon cycle model If you would also like to run CLIMBER-X with an interactive carbon cycle, then the HAMOCC ocean biogeochemistry ( bgc ) code must also be downloaded: # bgc cd src/ git clone git@github.com:cxesmc/bgc.git cd .. Since the HAMOCC model source code is not open source, the bgc repository is private at the moment and you need to be given permission in order to access it. HAMOCC is covered by the Max Planck Institute for Meteorology software licence agreement as part of the MPI-ESM ( https://code.mpimet.mpg.de/attachments/download/26986/MPI-ESM_SLA_v3.4.pdf ). A pre-requisite to access the bgc repository is therefore that you agree to the MPI-ESM license by following the steps outlined here: https://code.mpimet.mpg.de/projects/mpi-esm-license . Once you have done so, send us (whom?) an email and you will be granted permission to access the bgc repository. Note that you will need a GitHub account for that. # Compile the climate and carbon cycle model make clean make climber-clim-bgc # Run a pre-industrial equilibrium simulation with ocean biogeochemistry ./job_climber -s -f -o output/clim-bgc -c short -j parallel -n 16 \\&control=\"flag_bgc=T\" CLIMBER-X climate and ice sheet model If you would also like to run with an interactive ice sheet, then the lis library must be installed, the Yelmo ice-sheet code must be downloaded and configured and the solid Earth model VILMA libraries must be downloaded before compiling: # lis cd src/utils git clone git@github.com:anishida/lis.git lis-2.1.5 cd lis-2.1.5 ./configure --prefix=$PWD/../lis --enable-omp --enable-f90 CC=icc FC=ifort make make install cd ../../.. # yelmo cd src git clone git@github.com:palma-ice/yelmo.git cd yelmo git checkout climber-x # Get climber-x branch python config.py config/pik_ifort cd ../.. # vilma cd src/ git clone git@github.com:cxesmc/vilma.git # private repository, premission needed cd .. # Compile the climate and ice sheet model make clean make climber-clim-ice # Run pre-industrial equilibrium simulation with interactive Greenland ice sheet ./job_climber -s -f -o output/clim-ice -c short -j parallel -n 16 \\&control=\"flag_ice=T flag_geo=T flag_smb=T flag_imo=T ice_model_name=yelmo ice_domain_name=GRL-16KM\" Fully coupled CLIMBER-X configuration If you have followed all steps above you will also be ready to run fully coupled simulations: # Compile the fully coupled model make clean make climber-clim-bgc-ice # or equivalently make climber # Run pre-industrial equilibrium simulation with ocean biogeochemistry and interactive Greenland ice sheet ./job_climber -s -f -o output/clim-bgc-ice -c short -j parallel -n 16 \\&control=\"flag_bgc=T flag_ice=T flag_geo=T flag_smb=T flag_imo=T ice_model_name=yelmo ice_domain_name=GRL-16KM\"","title":"Running CLIMBER-X on the HPC2015 at PIK"},{"location":"running-at-pik_old/#running-climber-x-on-the-hpc2015-at-pik","text":"Here you can find the basic information and steps needed to get CLIMBER-X running on the (old) HPC2015 at PIK.","title":"Running CLIMBER-X on the HPC2015 at PIK"},{"location":"running-at-pik_old/#get-the-code","text":"","title":"Get the code"},{"location":"running-at-pik_old/#climber-x-climate-model","text":"### Download the CLIMBER-X code ### # Clone repository git clone git@github.com:cxesmc/climber-x.git # Enter directory cd climber-x # Clone input file directory git clone git@gitlab.pik-potsdam.de:cxesmc/climber-x-input.git input # Run configuration script python config.py config/pik_ifort ### Download and configure additional libraries ### # fftw cd src/utils/ wget https://www.fftw.org/fftw-3.3.10.tar.gz tar -xvf fftw-3.3.10.tar.gz rm fftw-3.3.10.tar.gz mv fftw-3.3.10 fftw cd fftw ./configure --prefix=$PWD --enable-openmp CC=icc F77=ifort make make install cd ../../.. # Return to climber-x parent directory # coordinates cd src/utils/ git clone git@github.com:cxesmc/coordinates.git cd coordinates python config.py config/pik_ifort cd ../../.. # Return to climber-x parent directory ### Compile and run ### # Compile the climate model make cleanall make climber-clim # Run a pre-industrial equilibrium climate-only test simulation ./job_climber -s -f -o output/clim -c short -j parallel -n 16","title":"CLIMBER-X climate model"},{"location":"running-at-pik_old/#climber-x-climate-and-carbon-cycle-model","text":"If you would also like to run CLIMBER-X with an interactive carbon cycle, then the HAMOCC ocean biogeochemistry ( bgc ) code must also be downloaded: # bgc cd src/ git clone git@github.com:cxesmc/bgc.git cd .. Since the HAMOCC model source code is not open source, the bgc repository is private at the moment and you need to be given permission in order to access it. HAMOCC is covered by the Max Planck Institute for Meteorology software licence agreement as part of the MPI-ESM ( https://code.mpimet.mpg.de/attachments/download/26986/MPI-ESM_SLA_v3.4.pdf ). A pre-requisite to access the bgc repository is therefore that you agree to the MPI-ESM license by following the steps outlined here: https://code.mpimet.mpg.de/projects/mpi-esm-license . Once you have done so, send us (whom?) an email and you will be granted permission to access the bgc repository. Note that you will need a GitHub account for that. # Compile the climate and carbon cycle model make clean make climber-clim-bgc # Run a pre-industrial equilibrium simulation with ocean biogeochemistry ./job_climber -s -f -o output/clim-bgc -c short -j parallel -n 16 \\&control=\"flag_bgc=T\"","title":"CLIMBER-X climate and carbon cycle model"},{"location":"running-at-pik_old/#climber-x-climate-and-ice-sheet-model","text":"If you would also like to run with an interactive ice sheet, then the lis library must be installed, the Yelmo ice-sheet code must be downloaded and configured and the solid Earth model VILMA libraries must be downloaded before compiling: # lis cd src/utils git clone git@github.com:anishida/lis.git lis-2.1.5 cd lis-2.1.5 ./configure --prefix=$PWD/../lis --enable-omp --enable-f90 CC=icc FC=ifort make make install cd ../../.. # yelmo cd src git clone git@github.com:palma-ice/yelmo.git cd yelmo git checkout climber-x # Get climber-x branch python config.py config/pik_ifort cd ../.. # vilma cd src/ git clone git@github.com:cxesmc/vilma.git # private repository, premission needed cd .. # Compile the climate and ice sheet model make clean make climber-clim-ice # Run pre-industrial equilibrium simulation with interactive Greenland ice sheet ./job_climber -s -f -o output/clim-ice -c short -j parallel -n 16 \\&control=\"flag_ice=T flag_geo=T flag_smb=T flag_imo=T ice_model_name=yelmo ice_domain_name=GRL-16KM\"","title":"CLIMBER-X climate and ice sheet model"},{"location":"running-at-pik_old/#fully-coupled-climber-x-configuration","text":"If you have followed all steps above you will also be ready to run fully coupled simulations: # Compile the fully coupled model make clean make climber-clim-bgc-ice # or equivalently make climber # Run pre-industrial equilibrium simulation with ocean biogeochemistry and interactive Greenland ice sheet ./job_climber -s -f -o output/clim-bgc-ice -c short -j parallel -n 16 \\&control=\"flag_bgc=T flag_ice=T flag_geo=T flag_smb=T flag_imo=T ice_model_name=yelmo ice_domain_name=GRL-16KM\"","title":"Fully coupled CLIMBER-X configuration"},{"location":"var-list/","text":"Variables list Atmosphere atm_ts.nc atm.nc Variable Dimension Description Unit fw_atl_indpac 2d Freshwater transport from Atlantic to Indo-Pacific catchment Sv fw_pac_atl 2d Freshwater transport from Pacific to Atlantic catchment Sv had_fi Deg had_width Deg acbarz 3d Zonal mean cross-isobar angle Rad coszm 3d Radiation weighted daily mean cosine of solar zenith angle ekez 3d Zonal mean eddy kinetic energy M2/s2 faycptg 3d Meridional cp*T transport by mean circulation PW faydseg 3d Meridional dry static energy transport by mean circulation PW fayg fayleg 3d Meridional latent heat transport by mean circulation PW faywtrg 3d Meridional moisture transport by mean circulation Kg/s frlnd 3d Land fraction in grid cell frocn 3d Ocean fraction in grid cell fyseg 3d Total meridional dry static energy transport PW fyheatg 3d Total meridional heat transport PW fyleg 3d Total meridional latent heat transport PW fywtrg 3d Total meridional moisture transport Kg/s ptrop 3d Relative pressure at tropopause slope 3d Topography slope m/m slope_x 3d Topography slope in zonal direction m/m slope_y 3d Topography slope in meridional direction m/m slpz 3d Zonal mean sea level pressure Pa solarm 3d Daily mean TOA incoming solar radiation W/m2 tskslz 3d Zonal mean skin temperature reduced to sea level K tslz 3d Zonal mean sea level temperature K uz500 3d Zonal mean 500 hPa zonal wind m/s uz850 3d Zonal mean 850 hPa zonal wind m/s vabz 3d Zonal mean meridional ageostrophic wind in PBL m/s zsa 3d Grid cell average surface elevation M zsa_smooth 3d Grid cell average smoothed surface elevation M ri 4d Bulk Richardson number acbar 4d Cross-isobar angle Rad alb_cld 4d Cloud albedo alb_plan 4d Planetary albedo alb_sur_cld 4d Cloudy-sky surface albedo alb_sur_cs 4d Clear-sky surface albedo aslp 4d Azonal sea level pressure Pa aslp_temp 4d Azonal sea level pressure from azonal temperature Pa aslp_topo 4d Azonal sea level pressure from topographic stationary waves Pa atsksl 4d Azonal sea level temperature K atsl 4d Azonal sea level temperature K atsli 4d Azonal sea level temperature K cd0a 4d Grid-cell average drag coefficient without orographic component cda 4d Grid-cell average drag coefficient cdif 4d Effective macrodiffusive coefficient M2/s cld 4d Total cloud fraction in grid cell cld_low 4d Total cloud fraction in grid cell cld_rh 4d Total cloud fraction in grid cell clot 4d Cloud optical thickness convadse 4d Column integrated dry static energy convergence by mean circulation W/m2 convawtr 4d Column integrated moisture convergence by mean circulation Kg/m2/day convddse 4d Column integrated dry static energy convergence by synoptic eddies convdwtr 4d Column integrated moisture convergence by synoptic eddies Kg/m2/s convwtr 4d Column integrated moisture convergence Kg/m2/day cosz 4d Cosine of solar zenith angle cre_sur 4d Cloud radiative effect at the surface W/m2 cre_top 4d Cloud radiative effect at TOA W/m2 ctt 4d Cloud top temperature K dam 4d Prognostic atmospheric dust mass mixing ratio Kg/kg diffxdse 4d Zonal effective macrodiffusivity for dry static energy M2/s diffxwtr 4d Zonal effective macrodiffusivity for dry water vapor M2/s dq 4d Specific humidity gradient between saturated skin and 2m Kg/kg dust_dep 4d Dust deposition Kg/m2/s dust_emis 4d Dust emissions Kg/m2/s dust_load 4d Atmospheric dust load Kg/m2 dust_ot 4d Dust optical thickness dz500 4d Azonal geopotential height at 500 hPa M eke 4d Eddy kinetic energy M2/s2 evpa 4d Grid-cell average evaporation Kg/m2/day fweff 4d Effective vertical velocity factor for cloud parametrization m/s gamb 4d Temperature lapse rate at the surface K/m gams 4d Temperature lapse rate in the boundary layer K/m hrm 4d Relative humidity height scale M lha 4d Grid-cell average surface latent heat flux W/m2 lwr_atm 4d Grid-cell average net longwave radiation at TOA W/m2 lwr_cre_sur 4d Longwave cloud radiative effect at the surface W/m2 prc 4d Total precipitation Kg/m2/day q2a 4d Grid-cell mean 2m specific humidity Kg/kg ra2a 4d Grid-cell average surface air density Kg/m3 rb_atm 4d Radiative balance of the atmosphere W/m2 rskin_ram 4d Atmospheric relative humidity sha 4d Grid-cell average surface sensible heat flux W/m2 slp 4d Sea level pressure Pa so4_ot 4d SO4 optical thickness solar 4d TOA incoming solar radiation W/m2 swr_atm 4d Grid-cell average net shortwave radiation at TOA W/m2 swr_cre_sur 4d Shortwave cloud radiative effect at the surface W/m2 t2a 4d Grid-cell mean 2m temperature K tam 4d Prognostic atmospheric temperature K uab 4d Zonal ageostrophic wind in the boundary layer m/s wind 4d 10m wind speed m/s wind_syn 4d Synoptic 10m wind m/s wcld 4d Vertical velocity at cloud level m/s xz 4d Mean meridional mass streamfunction Kg/s alb_ir_c 5d Near-infrared diffuse surface albedo for each macro surface type alb_vu_c 5d Visible surface albedo for each macro surface type fswr_sur 5d Net surface shortwave radiation for each surface type W/m2 t2 5d 2m temperature for each macro surface type K t3 5d 3d atmospheric temperature K taux 5d Zonal surface wind stress N/m2 tauy 5d Meridional surface wind stress N/m2 u3 5d 3d zonal wind m/s v3 5d 3d meridional wind m/s w3 5d 3d vertical velocity m/s","title":"Variables list"},{"location":"var-list/#variables-list","text":"","title":"Variables list"},{"location":"var-list/#atmosphere","text":"","title":"Atmosphere"},{"location":"var-list/#atm_tsnc","text":"","title":"atm_ts.nc"},{"location":"var-list/#atmnc","text":"Variable Dimension Description Unit fw_atl_indpac 2d Freshwater transport from Atlantic to Indo-Pacific catchment Sv fw_pac_atl 2d Freshwater transport from Pacific to Atlantic catchment Sv had_fi Deg had_width Deg acbarz 3d Zonal mean cross-isobar angle Rad coszm 3d Radiation weighted daily mean cosine of solar zenith angle ekez 3d Zonal mean eddy kinetic energy M2/s2 faycptg 3d Meridional cp*T transport by mean circulation PW faydseg 3d Meridional dry static energy transport by mean circulation PW fayg fayleg 3d Meridional latent heat transport by mean circulation PW faywtrg 3d Meridional moisture transport by mean circulation Kg/s frlnd 3d Land fraction in grid cell frocn 3d Ocean fraction in grid cell fyseg 3d Total meridional dry static energy transport PW fyheatg 3d Total meridional heat transport PW fyleg 3d Total meridional latent heat transport PW fywtrg 3d Total meridional moisture transport Kg/s ptrop 3d Relative pressure at tropopause slope 3d Topography slope m/m slope_x 3d Topography slope in zonal direction m/m slope_y 3d Topography slope in meridional direction m/m slpz 3d Zonal mean sea level pressure Pa solarm 3d Daily mean TOA incoming solar radiation W/m2 tskslz 3d Zonal mean skin temperature reduced to sea level K tslz 3d Zonal mean sea level temperature K uz500 3d Zonal mean 500 hPa zonal wind m/s uz850 3d Zonal mean 850 hPa zonal wind m/s vabz 3d Zonal mean meridional ageostrophic wind in PBL m/s zsa 3d Grid cell average surface elevation M zsa_smooth 3d Grid cell average smoothed surface elevation M ri 4d Bulk Richardson number acbar 4d Cross-isobar angle Rad alb_cld 4d Cloud albedo alb_plan 4d Planetary albedo alb_sur_cld 4d Cloudy-sky surface albedo alb_sur_cs 4d Clear-sky surface albedo aslp 4d Azonal sea level pressure Pa aslp_temp 4d Azonal sea level pressure from azonal temperature Pa aslp_topo 4d Azonal sea level pressure from topographic stationary waves Pa atsksl 4d Azonal sea level temperature K atsl 4d Azonal sea level temperature K atsli 4d Azonal sea level temperature K cd0a 4d Grid-cell average drag coefficient without orographic component cda 4d Grid-cell average drag coefficient cdif 4d Effective macrodiffusive coefficient M2/s cld 4d Total cloud fraction in grid cell cld_low 4d Total cloud fraction in grid cell cld_rh 4d Total cloud fraction in grid cell clot 4d Cloud optical thickness convadse 4d Column integrated dry static energy convergence by mean circulation W/m2 convawtr 4d Column integrated moisture convergence by mean circulation Kg/m2/day convddse 4d Column integrated dry static energy convergence by synoptic eddies convdwtr 4d Column integrated moisture convergence by synoptic eddies Kg/m2/s convwtr 4d Column integrated moisture convergence Kg/m2/day cosz 4d Cosine of solar zenith angle cre_sur 4d Cloud radiative effect at the surface W/m2 cre_top 4d Cloud radiative effect at TOA W/m2 ctt 4d Cloud top temperature K dam 4d Prognostic atmospheric dust mass mixing ratio Kg/kg diffxdse 4d Zonal effective macrodiffusivity for dry static energy M2/s diffxwtr 4d Zonal effective macrodiffusivity for dry water vapor M2/s dq 4d Specific humidity gradient between saturated skin and 2m Kg/kg dust_dep 4d Dust deposition Kg/m2/s dust_emis 4d Dust emissions Kg/m2/s dust_load 4d Atmospheric dust load Kg/m2 dust_ot 4d Dust optical thickness dz500 4d Azonal geopotential height at 500 hPa M eke 4d Eddy kinetic energy M2/s2 evpa 4d Grid-cell average evaporation Kg/m2/day fweff 4d Effective vertical velocity factor for cloud parametrization m/s gamb 4d Temperature lapse rate at the surface K/m gams 4d Temperature lapse rate in the boundary layer K/m hrm 4d Relative humidity height scale M lha 4d Grid-cell average surface latent heat flux W/m2 lwr_atm 4d Grid-cell average net longwave radiation at TOA W/m2 lwr_cre_sur 4d Longwave cloud radiative effect at the surface W/m2 prc 4d Total precipitation Kg/m2/day q2a 4d Grid-cell mean 2m specific humidity Kg/kg ra2a 4d Grid-cell average surface air density Kg/m3 rb_atm 4d Radiative balance of the atmosphere W/m2 rskin_ram 4d Atmospheric relative humidity sha 4d Grid-cell average surface sensible heat flux W/m2 slp 4d Sea level pressure Pa so4_ot 4d SO4 optical thickness solar 4d TOA incoming solar radiation W/m2 swr_atm 4d Grid-cell average net shortwave radiation at TOA W/m2 swr_cre_sur 4d Shortwave cloud radiative effect at the surface W/m2 t2a 4d Grid-cell mean 2m temperature K tam 4d Prognostic atmospheric temperature K uab 4d Zonal ageostrophic wind in the boundary layer m/s wind 4d 10m wind speed m/s wind_syn 4d Synoptic 10m wind m/s wcld 4d Vertical velocity at cloud level m/s xz 4d Mean meridional mass streamfunction Kg/s alb_ir_c 5d Near-infrared diffuse surface albedo for each macro surface type alb_vu_c 5d Visible surface albedo for each macro surface type fswr_sur 5d Net surface shortwave radiation for each surface type W/m2 t2 5d 2m temperature for each macro surface type K t3 5d 3d atmospheric temperature K taux 5d Zonal surface wind stress N/m2 tauy 5d Meridional surface wind stress N/m2 u3 5d 3d zonal wind m/s v3 5d 3d meridional wind m/s w3 5d 3d vertical velocity m/s","title":"atm.nc"}]}